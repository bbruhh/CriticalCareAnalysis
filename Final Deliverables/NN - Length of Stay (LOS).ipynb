{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - Length of Stay (LOS)\n",
    "\n",
    "This ML model predicts days from admission to discharge for the patients in the MIMIC dataset who lived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup\n",
    "Creates separate clean dataframes for both sets of patients - lived & died"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in labs\n",
    "\n",
    "labs = pd.read_csv('../Resources/labsNew.csv')\n",
    "labs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in patients that survived\n",
    "\n",
    "lived = pd.read_csv('../Resources/admissions_survived.csv')\n",
    "lived.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join labs.csv with the admissions_survived.csv\n",
    "\n",
    "lived_df = pd.merge(lived, labs, on='HADM_ID')\n",
    "lived_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check on what we have in our df\n",
    "\n",
    "lived_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of attributes we don't need and/or are messing up the model\n",
    "\n",
    "lived_df = lived_df.drop(['ROW_ID', 'SUBJECT_ID_x', 'HADM_ID', 'DIAGNOSIS', 'ADMITTIME', 'MARITAL_STATUS', 'DISCHTIME', 'DISCHARGE_LOCATION',\n",
    "                         'RELIGION', 'ETHNICITY', 'EDREGTIME', 'EDOUTTIME', 'HOSPITAL_EXPIRE_FLAG',\n",
    "       'HAS_CHARTEVENTS_DATA', 'SUBJECT_ID_y', 'LANGUAGE'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode non-numeric values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "x_data = lived_df.drop(['LENGTH_OF_STAY'], axis=1)\n",
    "encodedData = x_data.apply(LabelEncoder().fit_transform)\n",
    "encodedData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape the data\n",
    "\n",
    "X = encodedData\n",
    "y = lived_df['LENGTH_OF_STAY']\n",
    "print(f\"data shape: {X.shape}\")\n",
    "print(f\"target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Length of Stay Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test and train data and scale the data sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the NN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=14, activation='relu', input_dim=29))\n",
    "model.add(Dense(units=14, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the NN\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Was our model any good?\n",
    "\n",
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at first 5 predictions\n",
    "\n",
    "predictions = model.predict_classes(X_test[:5])\n",
    "\n",
    "print(f\"Predicted classes: {predictions}\")\n",
    "print(f\"Actual Labels: {list(y_test[:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"NeuralNetworkModels/LOS_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test a model, load the desired model and then run the cells below\n",
    "\n",
    "# ENTER THE NAME OF THE DESIRED MODEL TO LOAD HERE\n",
    "NNModel = \"LabValueModel#1.h5\"\n",
    "\n",
    "from keras.models import load_model\n",
    "first_model = load_model(f\"NeuralNetworkModels/{NNModel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss, model_accuracy = first_model.evaluate(\n",
    "    X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loaded Model Neural Network - Loss: {model_loss}, Loaded Model Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert AUROC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
